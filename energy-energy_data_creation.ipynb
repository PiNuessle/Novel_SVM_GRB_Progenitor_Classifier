{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da35bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Matching Fermi-GBM and Swift Data###\n",
    "import pandas as pd\n",
    "import math\n",
    "import gc\n",
    "import julian\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import scipy.stats as st\n",
    "import re\n",
    "import datetime\n",
    "from statistics import NormalDist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pdb\n",
    "import scipy.integrate as integrate\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data import##\n",
    "fermi_data=pd.read_csv('22_May_2023_Fermi_Data.csv')\n",
    "swift_data=pd.read_csv('real swift bat data 3.csv')\n",
    "swift_model_PL=pd.read_csv('swift_models_3_PL.csv')\n",
    "swift_model_CPL=pd.read_csv('swift_models_3_PL.csv')\n",
    "swift_fluxes_PL=pd.read_csv('swift_fluxes_3_PL.csv')\n",
    "swift_fluxes_CPL=pd.read_csv('swift_fluxes_3_PL.csv')\n",
    "swift_fluences_PL=pd.read_csv('swift_fluences_3_PL.csv')\n",
    "swift_fluences_CPL=pd.read_csv('swift_fluences_3_PL.csv')\n",
    "swift_fluences_reference=pd.read_csv('swift_fluences_3_match.csv')\n",
    "swift_redshifts=pd.read_csv('swift_redshifts.csv')\n",
    "second_redshifts=pd.read_csv(\"changed_alternative_GCN_redshifts.csv\")\n",
    "more_xrt_data=pd.read_csv('XRT_most_detailed_data.csv')\n",
    "weird_xrt_data=pd.DataFrame.copy(more_xrt_data)\n",
    "for k in range(0, len(weird_xrt_data)):\n",
    "    weird_xrt_data['GRB '][k]='0{}'.format(weird_xrt_data['GRB '][k])\n",
    "average_decay_data=pd.read_csv('Stage_2_decay_rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625aba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#God forbid I actually define a function#\n",
    "def singly_broken_PL(amplitude, break1, power1, power2, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def doubly_broken_PL(amplitude, break1, break2, power1, power2, power3, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def triply_broken_PL(amplitude, break1, break2, break3, power1, power2, power3, power4, t0,\\\n",
    "                     t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3:\n",
    "        value=amplitude*t**(power4)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def quadruply_broken_PL(amplitude, break1, break2, break3, break4, power1, power2, power3,\\\n",
    "                        power4, power5, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*t**(power4)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)\n",
    "    elif t>=break4:\n",
    "        value=amplitude*t**(power5)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)*break4**(power4-power5)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def quintuply_broken_PL(amplitude, break1, break2, break3, break4, break5, power1, power2,\\\n",
    "                        power3, power4, power5, power6, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*t**(power1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*t**(power2)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*t**(power3)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*t**(power4)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)\n",
    "    elif t>=break4 and t<break5:\n",
    "        value=amplitude*t**(power5)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)*break4**(power4-power5)\n",
    "    elif t>=break5:\n",
    "        value=amplitude*t**(power6)*break1**(power1-power2)*break2**(power2-power3)*\\\n",
    "                              break3**(power3-power4)*break4**(power4-power5)*\\\n",
    "                                break5**(power5-power6)\n",
    "    else:\n",
    "        value='N/A'\n",
    "    return value\n",
    "\n",
    "def defining_the_flux(tarjit, temporal_indices):\n",
    "    flux_catch=' Obs Flux_{} (pc) '.format(tarjit+1)\n",
    "    tarjete=tarjit+1\n",
    "    xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "    state=0\n",
    "    if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "        flux_catch=' Obs Flux_{} (wt) '.format(tarjit+1)\n",
    "        xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "        state=1\n",
    "        #weird case where sometimes XRT is still repointing or something, IDK.\n",
    "        #It nets us 220101A, which is what I wanted.\n",
    "    if tarjit==0:\n",
    "        if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "            flux_catch=' Obs Flux_{} (pc) '.format(tarjit+2)\n",
    "            xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "            tarjete=tarjit+2\n",
    "            state=0\n",
    "            if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "                flux_catch=' Obs Flux_{} (wt) '.format(tarjit+2)\n",
    "                xrt_flux=more_xrt_data[flux_catch][xrt_match]\n",
    "                state=1\n",
    "                #weird case where if it's at the very beginning, XRT\n",
    "                #might not be measuring flux yet\n",
    "    return flux_catch, xrt_flux, tarjete, state\n",
    "\n",
    "def HR_err_func(S_top, S_bot, sig_S_top, sig_S_bot):\n",
    "    HR_err=np.sqrt(np.power((sig_S_top/S_bot), 2)+np.power((S_top*sig_S_bot)/\\\n",
    "                                                          np.power(S_bot,2), 2))\n",
    "    return HR_err\n",
    "\n",
    "def Fermi_HR_func(relevant_fermi_data, spectral_model, entry):\n",
    "    low_e_range=[15, 150]\n",
    "    high_e_range=[150, 1500]\n",
    "    if spectral_model=='flnc_plaw              ' or spectral_model==1:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "        low_HR=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                              low_e_range[1]) #PL\n",
    "        high_HR=integrate.quad(lambda x: power_law(x, p_1), high_e_range[0], \\\n",
    "                              high_e_range[1]) #PL\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_comp              ' or spectral_model==2:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_comp_index'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "        low_HR=integrate.quad(lambda x:  Compton_PL(x, p_1, E_break), \\\n",
    "                       low_e_range[0], low_e_range[1]) #CPL\n",
    "        high_HR=integrate.quad(lambda x: Compton_PL(x, p_1, E_break), \\\n",
    "                       high_e_range[0], high_e_range[1]) #CPL\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_band              ' or spectral_model==3:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_band_alpha'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_band_beta'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "        low_HR=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       low_e_range[0], low_e_range[1]) #Band\n",
    "        high_HR=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       high_e_range[0], high_e_range[1]) #Band\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_sbpl              ' or spectral_model==4:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx1'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx2'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brken'])\n",
    "        smoothen=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brksc'])\n",
    "        low_HR=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen), \\\n",
    "                       low_e_range[0], low_e_range[1])\n",
    "        high_HR=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen),\\\n",
    "                       high_e_range[0], high_e_range[1])\n",
    "        HR=high_HR[0]/low_HR[0]\n",
    "        \n",
    "    else:\n",
    "        if relevant_fermi_data.at[entry, 'flnc_plaw_index']:\n",
    "            p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "            low_HR=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                                  low_e_range[1])\n",
    "            high_HR=integrate.quad(lambda x: power_law(x, p_1), \\\n",
    "                               high_e_range[0], high_e_range[1]) \n",
    "            #PL because that's the simplest one, unfortunately\n",
    "            HR=high_HR[0]/low_HR[0]\n",
    "        else:\n",
    "            HR=np.NA\n",
    "    return HR\n",
    "\n",
    "def swift_error_calculator(entry, fluence_table):\n",
    "    if fluence_table.at[entry, ' 50_100kev_low '] != ' N/A ':\n",
    "         HR_err_left = HR_err_func(float(fluence_table.at[entry, ' 50_100kev ']), \\\n",
    "                                float(fluence_table.at[entry, ' 25_50kev ']), \\\n",
    "                                float(fluence_table.at[entry,' 50_100kev_low ']), \\\n",
    "                                float(fluence_table.at[entry,' 25_50kev_low ']))\n",
    "#         HR_err_left = (float(fluence_table.at[entry,' 50_100kev '])-\\\n",
    "#                         float(fluence_table.at[entry, ' 50_100kev_low ']))/\\\n",
    "#                             (float(fluence_table.at[entry, ' 25_50kev '])-\\\n",
    "#                                    float(fluence_table.at[entry,' 25_50kev_low ']))\n",
    "    else:\n",
    "        HR_err_left = 0\n",
    "    if fluence_table.at[entry, ' 50_100kev_hi '] != ' N/A ':\n",
    "         HR_err_right=HR_err_func(float(fluence_table.at[entry, ' 50_100kev ']),\\\n",
    "                                 float(fluence_table.at[entry, ' 25_50kev ']), \\\n",
    "                                 float(fluence_table.at[entry,' 50_100kev_hi ']), \\\n",
    "                             float(fluence_table.at[entry,' 25_50kev_hi ']))\n",
    "#         HR_err_right = (float(fluence_table.at[entry, ' 50_100kev '])-\\\n",
    "#                         float(fluence_table.at[entry, ' 50_100kev_hi ']))/\\\n",
    "#                             (float(fluence_table.at[entry, ' 25_50kev '])-\\\n",
    "#                                    float(fluence_table.at[entry, ' 25_50kev_hi ']))\n",
    "    else:\n",
    "        HR_err_right = 0\n",
    "    return [HR_err_left, HR_err_right]\n",
    "\n",
    "def power_law (variable, index):\n",
    "    value=variable**index\n",
    "    return value\n",
    "\n",
    "def Compton_PL (variable, index, break_E):\n",
    "    value=np.power(variable, index)*np.exp(-variable/break_E)\n",
    "    return value\n",
    "\n",
    "def Band_function (variable, break_E, index_1, index_2):\n",
    "    index_1=abs(index_1)\n",
    "    index_2=abs(index_2)\n",
    "    value=np.where(variable < ((index_1-index_2)*break_E)/(index_1), \\\n",
    "        ((variable/100)**index_2)*np.exp(index_2-index_1)*(((index_1-index_2)*\\\n",
    "        break_E)/(100*(index_1)))**(index_1-index_2), ((variable/100)**index_1)*\\\n",
    "        np.exp(-((index_1)*variable)/break_E))\n",
    "    return np.real(value)\n",
    "\n",
    "def Smoothly_Broken_PL (variable, break_E, index_1, index_2, smoothen):\n",
    "    value=(variable/break_E)**(index_1)*(0.5*(1+(variable/break_E)**(1/smoothen)))**\\\n",
    "    (-(index_1-index_2)/smoothen)\n",
    "    return value\n",
    "\n",
    "def z_power_law(variable, index, redshift):\n",
    "    value=(variable*(1+redshift))**(index)\n",
    "    return value\n",
    "\n",
    "def swift_fluence_function(burst_index, column_name):\n",
    "    if swift_fluences_reference.at[burst_index, ' Best-fit model']==' PL':\n",
    "        fluence=swift_fluences_PL.at[burst_index, column_name]\n",
    "    elif swift_fluences_reference.at[burst_index, ' Best-fit model']==' CPL':\n",
    "        fluence=swift_fluences_CPL.at[burst_index, column_name]\n",
    "    else:\n",
    "        fluence=np.NaN\n",
    "    return fluence\n",
    "\n",
    "def swift_flux_function(burst_index, column_name):\n",
    "    if swift_fluences_reference.at[burst_index, ' Best-fit model']==' PL':\n",
    "        flux=swift_fluxes_PL.at[burst_index, column_name]\n",
    "    elif swift_fluences_reference.at[burst_index, ' Best-fit model']==' CPL':\n",
    "        flux=swift_fluxes_CPL.at[burst_index, column_name]\n",
    "    else:\n",
    "        flux=np.NaN\n",
    "    return flux\n",
    "\n",
    "def swift_model_function(burst_index, column_name):\n",
    "    if swift_fluences_reference.at[burst_index, ' Best-fit model']==' PL':\n",
    "        model=swift_model_PL.at[burst_index, column_name]\n",
    "    elif swift_fluences_reference.at[burst_index, ' Best-fit model']==' CPL':\n",
    "        model=swift_model_CPL.at[burst_index, column_name]\n",
    "    else:\n",
    "        model=np.NaN\n",
    "    return model\n",
    "\n",
    "def getting_the_GBM_E_peak(relevant_fermi_data, spectral_model, entry):\n",
    "    if spectral_model=='flnc_plaw              ' or spectral_model==1:\n",
    "        if relevant_fermi_data.at[entry, 'flnc_comp_epeak']:\n",
    "            E_peak=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "        elif relevant_fermi_data.at[entry, 'flnc_band_epeak']:\n",
    "            E_peak=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "        else:\n",
    "            E_peak=np.NaN\n",
    "    elif spectral_model=='flnc_comp              ' or spectral_model==2:\n",
    "        E_peak=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "    elif spectral_model=='flnc_band              ' or spectral_model==3:\n",
    "        E_peak=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "    elif spectral_model=='flnc_sbpl              ' or spectral_model==4:\n",
    "        E_peak=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brken'])\n",
    "    else:\n",
    "        E_peak=np.NaN\n",
    "    return E_peak\n",
    "\n",
    "def getting_the_BAT_E_peak(entry):\n",
    "    if swift_fluences_reference.at[entry, ' Best-fit model']==' CPL':\n",
    "        if swift_model_CPL.at[entry, ' Epeak '] != ' N/A ':\n",
    "            E_peak=float(swift_model_CPL.at[entry, ' Epeak '])\n",
    "        else:\n",
    "            E_peak= np.NaN\n",
    "    elif swift_fluences_reference.at[entry, ' Best-fit model']==' PL':\n",
    "        if swift_model_CPL.at[entry, ' Epeak ']:\n",
    "            if swift_model_CPL.at[entry, ' Epeak '] != ' N/A ':\n",
    "                E_peak=float(swift_model_CPL.at[entry, ' Epeak '])\n",
    "            else:\n",
    "                E_peak= np.NaN\n",
    "        else:\n",
    "            E_peak= np.NaN\n",
    "    else:\n",
    "        E_peak=np.NaN\n",
    "    return E_peak\n",
    "\n",
    "def Fermi_k_func(relevant_fermi_data, spectral_model, entry, redshift):\n",
    "#     pdb.set_trace()\n",
    "    low_e_range=[10, 1000]\n",
    "    high_e_range=[1/(1+redshift), 10000/(1+redshift)]\n",
    "    if spectral_model=='flnc_plaw              ' or spectral_model==1:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "        denominator=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                              low_e_range[1]) #PL\n",
    "        numerator=integrate.quad(lambda x: power_law(x, p_1), high_e_range[0], \\\n",
    "                              high_e_range[1]) #PL\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_comp              ' or spectral_model==2:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_comp_index'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_comp_epeak'])\n",
    "        denominator=integrate.quad(lambda x:  Compton_PL(x, p_1, E_break), \\\n",
    "                       low_e_range[0], low_e_range[1]) #CPL\n",
    "        numerator=integrate.quad(lambda x: Compton_PL(x, p_1, E_break), \\\n",
    "                       high_e_range[0], high_e_range[1]) #CPL\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_band              ' or spectral_model==3:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_band_alpha'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_band_beta'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_band_epeak'])\n",
    "        denominator=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       low_e_range[0], low_e_range[1]) #Band\n",
    "        numerator=integrate.quad(lambda x: Band_function(x, E_break, p_1, p_2), \\\n",
    "                       high_e_range[0], high_e_range[1]) #Band\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    elif spectral_model=='flnc_sbpl              ' or spectral_model==4:\n",
    "        p_1=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx1'])\n",
    "        p_2=float(relevant_fermi_data.at[entry, 'flnc_sbpl_indx2'])\n",
    "        E_break=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brken'])\n",
    "        smoothen=float(relevant_fermi_data.at[entry, 'flnc_sbpl_brksc'])\n",
    "        denominator=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen), \\\n",
    "                       low_e_range[0], low_e_range[1])\n",
    "        numerator=integrate.quad(lambda x: Smoothly_Broken_PL(x, E_break, p_1, p_2, smoothen),\\\n",
    "                       high_e_range[0], high_e_range[1])\n",
    "        k=numerator[0]/denominator[0]\n",
    "        \n",
    "    else:\n",
    "        if relevant_fermi_data.at[entry, 'flnc_plaw_index']:\n",
    "            p_1=float(relevant_fermi_data.at[entry, 'flnc_plaw_index'])\n",
    "            denominator=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                                  low_e_range[1])\n",
    "            numerator=integrate.quad(lambda x: power_law(x, p_1), \\\n",
    "                               high_e_range[0], high_e_range[1]) \n",
    "            #PL because that's the simplest one, unfortunately\n",
    "            k=numerator[0]/denominator[0]\n",
    "        else:\n",
    "            k=np.NA\n",
    "    return k\n",
    "\n",
    "def XRT_k_func(relevant_xrt_data, entry, redshift):\n",
    "#     pdb.set_trace()\n",
    "    low_e_range=[0.2, 10]\n",
    "    high_e_range=[0.2/(1+redshift), 10/(1+redshift)]\n",
    "    if float(relevant_xrt_data.at[entry, 'plaw_index']):\n",
    "        p_1=-abs(float(relevant_xrt_data.at[entry, 'plaw_index']))\n",
    "        denominator=integrate.quad(lambda x: power_law(x, p_1), low_e_range[0], \\\n",
    "                              low_e_range[1]) #PL\n",
    "        numerator=integrate.quad(lambda x: power_law(x, p_1), high_e_range[0], \\\n",
    "                              high_e_range[1]) #PL\n",
    "        k=np.real(numerator[0]/denominator[0])\n",
    "    else:\n",
    "        k=np.NaN\n",
    "    return k\n",
    "\n",
    "def kinetic_energy(nFn, beta, D_L, redshift, time, nu):\n",
    "#     pdb.set_trace()\n",
    "    time=((time/60)/60)/24\n",
    "    nu=nu/(10**18)\n",
    "    p=2*beta\n",
    "    Y=1\n",
    "    eps_e=0.1\n",
    "    eps_b=0.01\n",
    "    nFn_term=(nFn/(5.2*1e-14))**(4/(p+2))\n",
    "    dist_term=((D_L*1e-28)**(8/(p+2)))\n",
    "    rs_term=(1+redshift)**(-1)\n",
    "    time_term=(time**((3*p-2)/(p+2)))*(1+Y)**(4/(p+2))\n",
    "    if p != 2:\n",
    "        fluxy_term=((6.73*((p-2)/(p-1))**(p-1))*((3.3*1e-6)**((p-2.3)/2)))**(-4/(p+2))\n",
    "    else:\n",
    "        #This is jsut a guess around the value given the other results, \n",
    "        #since p=2 is a discountinuity\n",
    "        fluxy_term=((6.73*((p-1.9925)/(p-1))**(p-1))*((3.3*1e-6)**((p-2.3)/2)))**(-4/(p+2))\n",
    "    carrier_dens_terms=((eps_e*1e1)**((4*(1-p))/(p+2)))*(eps_b*1e2)**((2-p)/(p+2))\n",
    "    freq_term=(nu*1e-18)**((2*(p-2))/(p+2))\n",
    "    E_k=nFn_term*dist_term*rs_term*time_term*fluxy_term*carrier_dens_terms*freq_term\n",
    "    return E_k\n",
    "\n",
    "def efficiency(E_k, E_g):\n",
    "    eta=E_g/(E_g+E_k)\n",
    "    return eta\n",
    "\n",
    "def singly_broken_PL_derivative(amplitude, break1, power1, power2, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power_1*t**(power1-1)\n",
    "    elif t>=break1:\n",
    "        value=amplitude*power_2*t**(power2-1)*break1**(power1-power2)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def doubly_broken_PL_derivative(amplitude, break1, break2, power1, power2, power3, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power1*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)*\\\n",
    "        break2**(power2-power3)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def triply_broken_PL_derivative(amplitude, break1, break2, break3, power1, power2,\\\n",
    "                                power3, power4, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power1*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)\\\n",
    "        *break2**(power2-power3)\n",
    "    elif t>=break3:\n",
    "        value=amplitude*power4*t**(power4-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def quadruply_broken_PL_derivative(amplitude, break1, break2, break3, break4, power1,\\\n",
    "                                   power2, power3, power4, power5, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power3*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*power4*t**(power4-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)\n",
    "    elif t>=break4:\n",
    "        value=amplitude*power5*t**(power5-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)*break4**(power4-power5)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value\n",
    "\n",
    "def quintuply_broken_PL_derivative(amplitude, break1, break2, break3, break4, break5, \\\n",
    "                                   power1, power2, power3, power4, power5, power6, t0, t):\n",
    "    if t<break1 and t>t0:\n",
    "        value=amplitude*power1*t**(power1-1)\n",
    "    elif t>=break1 and t<break2:\n",
    "        value=amplitude*power2*t**(power2-1)*break1**(power1-power2)\n",
    "    elif t>=break2 and t<break3:\n",
    "        value=amplitude*power3*t**(power3-1)*break1**(power1-power2)*break2**(power2-power3)\n",
    "    elif t>=break3 and t<break4:\n",
    "        value=amplitude*power4*t**(power4-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)\n",
    "    elif t>=break4 and t<break5:\n",
    "        value=amplitude*power5*t**(power5-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)*break4**(power4-power5)\n",
    "    elif t>=break5:\n",
    "        value=amplitude*power6*t**(power6-1)*break1**(power1-power2)*break2**(power2-power3)\\\n",
    "        *break3**(power3-power4)*break4**(power4-power5)*break5**(power5-power6)\n",
    "    else:\n",
    "        value=np.NaN\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yeah, this dictionary will make life 500x easier later\n",
    "Known_Precursors = {}\n",
    "Known_Precursors[\"Long Collapsars\"] = ('GRB050416A   ', 'GRB081007   ', 'GRB091127   ', \\\n",
    "                                       'GRB050525A   ', 'GRB050824   ', 'GRB060218   ', \\\n",
    "                                       'GRB060729   ', 'GRB060904B   ', 'GRB070419A   ', \\\n",
    "                                       'GRB071025   ', 'GRB071112C   ', 'GRB080109   ', \\\n",
    "                                       'GRB080319B   ', 'GRB081007A   ', 'GRB090618   ', \\\n",
    "                                       'GRB091127   ', 'GRB100316D   ', 'GRB100418A   ', \\\n",
    "                                       'GRB101219B   ', 'GRB101225A   ', 'GRB111209A   ', \\\n",
    "                                       'GRB111211A   ', 'GRB111228A   ', 'GRB120422A   ', \\\n",
    "                                       'GRB120714B   ', 'GRB120729A   ', 'GRB130215A   ', \\\n",
    "                                       'GRB130427A   ', 'GRB130702A   ', 'GRB130831A   ', \\\n",
    "                                       'GRB140206A   ', 'GRB140606B   ', 'GRB150818A   '\\\n",
    "                                       'GRB161219B   ', 'GRB161228B   ', 'GRB171010A   ', \\\n",
    "                                       'GRB171205A   ', 'GRB180720B   ', 'GRB180728A   ', \\\n",
    "                                       'GRB190114C   ', 'GRB190829A   ', 'GRB221009A   ', \\\n",
    "                                       'GRB211023A   ', 'GRB200826A   ', 'GRB210210A   ')\n",
    "Known_Precursors[\"Short Collapsars\"] = ('GRB200826A   ')\n",
    "Known_Precursors[\"Short Mergers\"] = ('GRB130603B   ', 'GRB160821B   ', 'GRB200522A   ', \\\n",
    "                                     'GRB150101B   ', 'GRB160624A   ', 'GRB170817A   ', \\\n",
    "                                     'GRB070809   ')\n",
    "Known_Precursors[\"Long Mergers\"] = ('GRB211211A   ', 'GRB230307A   ', 'GRB120304B   ', \\\n",
    "                                    'GRB111005A   ', 'GRB060614   ')\n",
    "Known_Precursors[\"Potentially Exotic\"] = (\"GRB210704A   \")\n",
    "Known_Precursors[\"Galactic Detected\"] = (\"GRB050509B   \", \"GRB050709   \", \"GRB051210    \", \\\n",
    "                                         \"GRB070714B   \", \"GRB071227    \", \"GRB080503    \", \\\n",
    "                                         \"GRB080905A   \", \"GRB090515    \", \"GRB160303A   \")\n",
    "###\n",
    "Fermi_Precursors = {}\n",
    "Fermi_Precursors[\"Long Collapsars\"] = ('GRB050416461', 'GRB050525002', 'GRB050824966', \\\n",
    "                                       'GRB060218148', 'GRB060729800', 'GRB060904104', \\\n",
    "                                       'GRB070419447', 'GRB071025172', 'GRB071112772', \\\n",
    "                                       'GRB080319258', 'GRB081007224', 'GRB090618353', \\\n",
    "                                       'GRB091127976', 'GRB100316531', 'GRB100418882', \\\n",
    "                                       'GRB101219686', 'GRB101225776', 'GRB111209300', \\\n",
    "                                       'GRB111211928', 'GRB111228656', 'GRB120422300', \\\n",
    "                                       'GRB120714888', 'GRB120729455', 'GRB130215063', \\\n",
    "                                       'GRB130427324', 'GRB130702003', 'GRB130831544', \\\n",
    "                                       'GRB140206303', 'GRB140606133', 'GRB150818483', \\\n",
    "                                       'GRB161219783', 'GRB161228552' ,'GRB171010792', \\\n",
    "                                       'GRB171205306', 'GRB180720598', 'GRB180728728', \\\n",
    "                                       'GRB190114872', 'GRB190829830', 'GRB200826187', \\\n",
    "                                       'GRB210210083', 'GRB211023545', 'GRB221009553')\n",
    "Fermi_Precursors[\"Short Collapsars\"] = ('GRB200826187')\n",
    "Fermi_Precursors[\"Short Mergers\"] = ('GRB070809807', 'GRB130603659', 'GRB150101641', \\\n",
    "                                     'GRB160624477', 'GRB160821936', 'GRB170817528', \\\n",
    "                                     'GRB200522487')\n",
    "Fermi_Precursors[\"Long Mergers\"] = ('GRB060614530', 'GRB111005336', 'GRB120304248', \\\n",
    "                                    'GRB211211548', 'GRB230307655')\n",
    "Fermi_Precursors[\"Potentially Exotic\"] = ('GRB210704814')\n",
    "Fermi_Precursors[\"Galactic Detected\"] = ('GRB050509166', 'GRB050709942', 'GRB051210240', \\\n",
    "                                         'GRB070714207', 'GRB071227842', 'GRB080503518', \\\n",
    "                                         'GRB080905499', 'GRB090515198', 'GRB160303454')\n",
    "###\n",
    "Overlap_Precursors = {}\n",
    "Overlap_Precursors[\"Long Collapsars\"] = (050416461.0, 50525002.0, 050824966.0, \\\n",
    "                                       060218148.0, 060729800.0, 060904104.0, \\\n",
    "                                       070419447.0, 071025172.0, 071112772.0, \\\n",
    "                                       080319258.0, 081007224.0, 090618353.0, \\\n",
    "                                       091127976.0, 100316531.0, 100418882.0, \\\n",
    "                                       101219686.0, 101225776.0, 111209300.0, \\\n",
    "                                       111211928.0, 111228656.0, 120422300.0, \\\n",
    "                                       120714888.0, 120729455.0, 130215063.0, \\\n",
    "                                       130427324.0, 130702003.0, 130831544.0, \\\n",
    "                                       140206303.0, 140606133.0, 150818483.0, \\\n",
    "                                       161219783.0, 161228552.0, 171010792.0, \\\n",
    "                                       171205306.0, 180720598.0, 180728728.0, \\\n",
    "                                       190114872.0, 190829830.0, 200826187.0, \\\n",
    "                                       210210083.0, 211023545.0, 221009553.0)\n",
    "Overlap_Precursors[\"Short Collapsars\"] = (200826187.0)\n",
    "Overlap_Precursors[\"Short Mergers\"] = (070809807.0, 130603659.0, 150101641.0, \\\n",
    "                                     160624477.0, 160821936.0, 170817528.0, \\\n",
    "                                     200522487.0)\n",
    "Overlap_Precursors[\"Long Mergers\"] = (060614530.0, 111005336.0, 120304248.0, \\\n",
    "                                    211211548.0, 230307655.0)\n",
    "Overlap_Precursors[\"Potentially Exotic\"] = (210704814.0)\n",
    "Overlap_Precursors[\"Galactic Detected\"] = (050509166.0, 050709942.0, 051210240.0, \\\n",
    "                                         070714207.0, 071227842.0, 080503518.0, \\\n",
    "                                         080905499.0, 090515198.0, 160303454.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f9119",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating Sample 0##\n",
    "tiny_removals=[]\n",
    "singular_swift_fluences_list=np.zeros((1,8))\n",
    "singular_swift_fluxes_list=np.zeros((1,4))\n",
    "singular_swift_models_list=np.zeros((1,7))\n",
    "tarjete=0\n",
    "stage=0\n",
    "for i in range(0,len(swift_fluences_reference)):\n",
    "    #for each event\n",
    "    placeholder=[[swift_data.at[i, 'GRBname '], swift_fluence_function(i, ' 25_50kev '), \\\n",
    "                swift_fluence_function(i, ' 25_50kev_low '), \\\n",
    "                swift_fluence_function(i, ' 25_50kev_hi '), \\\n",
    "                swift_fluence_function(i, ' 50_100kev '),\\\n",
    "                                          swift_fluence_function(i, ' 50_100kev_low '),\\\n",
    "                                          swift_fluence_function(i, ' 50_100kev_hi '), \n",
    "                                          swift_fluence_function(i, ' 15_350kev ')]]\n",
    "    singular_swift_fluences_list=np.append(singular_swift_fluences_list, \\\n",
    "                placeholder, axis=0)\n",
    "    other_placeholder=[[swift_data.at[i, 'GRBname '], swift_flux_function(i, ' 15_350kev '), \\\n",
    "                swift_fluence_function(i, ' 15_350kev_low '), \\\n",
    "                swift_fluence_function(i, ' 15_350kev_hi ')]]\n",
    "    singular_swift_fluxes_list=np.append(singular_swift_fluxes_list, \\\n",
    "                other_placeholder, axis=0)\n",
    "    third_placeholder=[[swift_data.at[i, 'GRBname '], swift_model_function(i, ' alpha '), \\\n",
    "                swift_model_function(i, ' alpha_low '), \\\n",
    "                        swift_model_function(i, ' alpha_hi '), \\\n",
    "                        swift_model_function(i, ' Epeak '), \\\n",
    "                        swift_model_function(i, ' Epeak_low '), \\\n",
    "                        swift_model_function(i, ' Epeak_hi ')]]\n",
    "    singular_swift_models_list=np.append(singular_swift_models_list, \\\n",
    "                third_placeholder, axis=0)\n",
    "singular_swift_fluences_list=singular_swift_fluences_list[1:]\n",
    "singular_swift_fluxes_list=singular_swift_fluxes_list[1:]\n",
    "singular_swift_models_list=singular_swift_models_list[1:]\n",
    "swift_fluences=pd.DataFrame(singular_swift_fluences_list, columns=['GRBname ', ' 25_50kev ',\\\n",
    "                                                                  ' 25_50kev_low ', \\\n",
    "                                                                   ' 25_50kev_hi ', \\\n",
    "                                                                   ' 50_100kev ', \\\n",
    "                                                                   ' 50_100kev_low ', \\\n",
    "                                                                   ' 50_100kev_hi ', \\\n",
    "                                                                   ' 15_350kev '])\n",
    "swift_fluxes=pd.DataFrame(singular_swift_fluxes_list, columns=['GRBname ', ' 15_350kev ',\\\n",
    "                                                                  ' 15_350kev_low ', \\\n",
    "                                                                   ' 15_350kev_hi '])\n",
    "swift_models=pd.DataFrame(singular_swift_models_list, columns=['GRBname ', ' alpha ', \\\n",
    "                                                               ' alpha_low ', \\\n",
    "                                                               ' alpha_hi ', \\\n",
    "                                                              ' E_peak ', ' E_peak_low ', \\\n",
    "                                                              ' E_peak_hi '])\n",
    "for i in range(0,len(swift_fluences_reference)):\n",
    "    test_flux=swift_fluxes.at[i,' 15_350kev ']\n",
    "    test_direction=swift_data['  RA_ground   '][i]\n",
    "    test_time=swift_data['     T90      '][i]\n",
    "    if test_direction==' N/A ' or test_direction=='N/A':\n",
    "            tiny_removals.append(i)\n",
    "    elif test_time==' N/A ' or test_time=='N/A':\n",
    "            tiny_removals.append(i)\n",
    "    elif test_flux==' N/A ':\n",
    "            tiny_removals.append(i)\n",
    "if (len(swift_fluxes)-1)<(len(swift_data)-1):\n",
    "    for k in range(len(swift_fluxes)-1, len(swift_data)):\n",
    "        tiny_removals.append(k)\n",
    "sample_0_data = swift_data.drop(index=tiny_removals)\n",
    "print(len(sample_0_data))\n",
    "print(len(swift_fluences))\n",
    "print(len(swift_fluxes))\n",
    "print(len(swift_models))\n",
    "print(len(swift_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25794cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating Samples 1 and 4##\n",
    "removals=[]\n",
    "xrt_matches=np.zeros((1,2))\n",
    "xrt_stages=np.zeros((1,2))\n",
    "xrt_avg_slope=np.zeros((1,2))\n",
    "tarjete=0\n",
    "stage=0\n",
    "for i in range(0,len(swift_fluxes)):\n",
    "    #for each event\n",
    "    query=swift_data[' XRT_detection '][i]\n",
    "    #query the XRT detection then add it to the first empty list\n",
    "    #print(swift_fluxes.at[i,' 15_350kev '])\n",
    "    test_flux=swift_fluxes.at[i,' 15_350kev ']\n",
    "    test_direction=swift_data['  RA_ground   '][i]\n",
    "    test_time=swift_data['     T90      '][i]\n",
    "    #snap=swift_data['GRBname '][i].strip()[3:]\n",
    "    #pdb.set_trace()\n",
    "#     if swift_data['GRBname '][i]=='GRB080503    ':\n",
    "#         pdb.set_trace()\n",
    "    if len(np.where(swift_data['GRBname '][i].strip()[3:]==more_xrt_data['GRB '])[0])>0 \\\n",
    "    or len(np.where(swift_data['GRBname '][i][3:].strip()==weird_xrt_data['GRB '])[0])>0:\n",
    "#         if swift_data['GRBname '][i].strip()[3:]=='211211A':\n",
    "#             pdb.set_trace()\n",
    "        if len(np.where(swift_data['GRBname '][i].strip()[3:]==more_xrt_data['GRB '])[0])>0:\n",
    "            xrt_match=np.where(swift_data['GRBname '][i].strip()[3:]==\\\n",
    "                               more_xrt_data['GRB '])[0][0]\n",
    "        elif len(np.where(swift_data['GRBname '][i].strip()[3:]==\\\n",
    "                          weird_xrt_data['GRB '])[0])>0:\n",
    "            xrt_match=np.where(swift_data['GRBname '][i].strip()[3:]==\n",
    "                               weird_xrt_data['GRB '])[0][0]\n",
    "        #         xrt_trigger=xrt_data['Trigger Number'][xrt_match]\n",
    "#         test_pindex=swift_pindex['GRB'][xrt_match]\n",
    "#         xrt_flux=more_xrt_data[' Obs Flux_2 (pc) '][xrt_match]\n",
    "        #they're off becuase I downloaded them at different times.\n",
    "#         if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "#             removals.append(i)\n",
    "        temporal_indices=np.zeros(6)\n",
    "        for l in range(0, 6):\n",
    "            flux_name=' alpha_{} '.format(l+1)\n",
    "            if more_xrt_data[flux_name][xrt_match]==' N/A ' \\\n",
    "                or more_xrt_data[flux_name][xrt_match]=='N/A' \\\n",
    "                or more_xrt_data[flux_name][xrt_match]=='NaN':\n",
    "                temporal_indices[l]=-100 #just throw it out of range\n",
    "            else:\n",
    "                temporal_indices[l]=more_xrt_data[flux_name][xrt_match]\n",
    "        if len(np.where((temporal_indices > -0.75) & (temporal_indices < 0.75))[0])>0:\n",
    "            tarjit=np.where((temporal_indices > -0.75) & (temporal_indices < 0.75))[0][0]\n",
    "            flux_catch, xrt_flux, tarjete, state=defining_the_flux(tarjit, temporal_indices)\n",
    "            slope_index=[]\n",
    "            slope_sum=0\n",
    "            for m in range(0, 6):\n",
    "                if m==tarjit-1:\n",
    "                    continue\n",
    "                elif temporal_indices[m]==-100:\n",
    "                    continue\n",
    "                else:\n",
    "                    slope_index=np.append(slope_index, temporal_indices[m])\n",
    "            if len(slope_index)>0:\n",
    "                slope_sum=np.average(slope_index)\n",
    "            else:\n",
    "                slope_sum=0\n",
    "#         elif (np.where(abs(temporal_indices)==min(abs(temporal_indices)))[0][0]>0) and \\\n",
    "#         min(abs(temporal_indices))<100:\n",
    "#             tarjit=np.where(abs(temporal_indices)==min(abs(temporal_indices)))[0][0]\n",
    "#             flux_catch, xrt_flux, tarjete, state=defining_the_flux(tarjit, temporal_indices)\n",
    "        else:\n",
    "            xrt_flux=' N/A '\n",
    "        if xrt_flux==' N/A ' or xrt_flux=='N/A' or xrt_flux=='NaN':\n",
    "            removals.append(i)\n",
    "            #anyway, we don't wnat the ones without flux right now\n",
    "#         elif test_pindex==' N/A ' or test_pindex=='N/A' or test_pindex=='NaN':\n",
    "#             removals.append(i)\n",
    "#         elif query!='Yes' and query!=' Yes ':\n",
    "#             #and add it to the second one if it didn't detect or it's not sure\n",
    "#             removals.append(i)\n",
    "        if test_flux==' N/A ':\n",
    "            removals.append(i)\n",
    "        elif test_direction==' N/A ' or test_direction=='N/A':\n",
    "            removals.append(i)\n",
    "        elif test_time==' N/A ' or test_time=='N/A' or test_time=='     N/A      ':\n",
    "            removals.append(i)\n",
    "#         elif xrt_trigger=='BAT/GUANO':\n",
    "            #These ones probably won't show up in the the data, but I don't want them\n",
    "            #because they aren't relevant to what I'm doing, being that they /probably/ \n",
    "            #aren't triggered by Fermi and the data ends up missing everything relevant\n",
    "#             removals.append(i)\n",
    "        else:\n",
    "            xrt_matches=np.append(xrt_matches,[[int(i),int(xrt_match)]], axis=0)\n",
    "            xrt_stages=np.append(xrt_stages,[[int(state),int(tarjete)]], axis=0)\n",
    "#             xrt_avg_slope=np.append(xrt_avg_slope,[[int(i),int(slope_sum)]], axis=0)\n",
    "            continue\n",
    "    else:\n",
    "        removals.append(i)\n",
    "if (len(swift_fluxes)-1)<(len(swift_data)-1):\n",
    "    for k in range(len(swift_fluxes)-1, len(swift_data)):\n",
    "        removals.append(k)\n",
    "edited_swift_data = swift_data.drop(index=removals)\n",
    "xrt_matches=xrt_matches[1:]\n",
    "xrt_stages=xrt_stages[1:]\n",
    "# xrt_avg_slope=xrt_avg_slope[1:]\n",
    "test_flux=[]\n",
    "for j in edited_swift_data.index:\n",
    "    test_flux.append(swift_fluxes.at[j,' 15_350kev '])\n",
    "red_swift_removals=[]\n",
    "r=0\n",
    "redshift_matches=np.zeros((1,2))\n",
    "redshift_xrt=np.zeros((1,2))\n",
    "redshift_stages=np.zeros((1,2))\n",
    "# redshift_avg_slope=np.zeros((1,2))\n",
    "for j in edited_swift_data.index:\n",
    "    for i in range(0, len(swift_redshifts)):\n",
    "        swift_string=edited_swift_data['GRBname '][j].strip()\n",
    "        redshift_string=swift_redshifts['GRBname '][i].strip()\n",
    "        redsweefer = swift_redshifts.at[i, ' z '] #I call a swiffer a sweefer and \n",
    "        #this error was going to be a serious issue unlike the stupid question marks\n",
    "        if swift_string==redshift_string:\n",
    "            redshift_matches=np.append(redshift_matches,[[int(i),int(j)]], axis=0)\n",
    "            row_match=int(np.where(xrt_matches[:, 0]==j)[0][0])\n",
    "            redshift_xrt=np.append(redshift_xrt,[[int(j),xrt_matches[row_match,1]]], \\\n",
    "                                       axis=0)\n",
    "            redshift_stages=np.append(redshift_stages,[[int(xrt_stages[row_match,0]),\n",
    "                                                        int(xrt_stages[row_match,1])]], \\\n",
    "                                      axis=0)\n",
    "#             redshift_avg_slope=np.append(redshift_avg_slope,[[int(i),\\\n",
    "#                                                     int(xrt_avg_slope[row_match, 1])]],\\\n",
    "#                                          axis=0)\n",
    "            if 'or' in str(redsweefer):\n",
    "#                 print(redsweefer)\n",
    "#                 print(redshift_string)\n",
    "                red_swift_removals.append(j)\n",
    "                redshift_xrt=redshift_xrt[:len(redshift_xrt)-1,:]\n",
    "                redshift_stages=redshift_stages[:len(redshift_stages)-1,:]\n",
    "#                 redshift_avg_slope=redshift_avg_slope[:len(redshift_stages)-1,:]\n",
    "            if '-' in str(redsweefer):\n",
    "                #whatever jerk did this one is okay in my book, not like ALL THE OTHER AWFUL\n",
    "                #NONNUMERIC CHARACTERS AHHHHHHHHH, jerks, all the rest of you\n",
    "                redswiffer=re.split(\"-\", redsweefer.strip())\n",
    "                red_broom = list(map(float, redswiffer))\n",
    "                swift_redshifts.at[i, ' z ']=np.mean([red_broom[0], red_broom[1]])\n",
    "            break\n",
    "        elif swift_string != redshift_string and i==len(swift_redshifts)-1:\n",
    "            r=r+1\n",
    "            red_swift_removals.append(j)\n",
    "        else: \n",
    "            continue\n",
    "other_redshift_matches=np.zeros((1,2))\n",
    "for j in edited_swift_data.index:\n",
    "    for i in range(0, len(second_redshifts)):\n",
    "        swift_string_2=edited_swift_data['GRBname '][j].strip()\n",
    "        redshift_string_2=second_redshifts['GRB'][i].strip()\n",
    "        redmop = second_redshifts.at[i, 'zc']\n",
    "        if swift_string_2==redshift_string_2:\n",
    "            other_redshift_matches=np.append(other_redshift_matches,[[int(i),int(j)]], axis=0)\n",
    "            if type(red_swift_removals)!=int:\n",
    "                if len(np.where(red_swift_removals==j)[0])>0:\n",
    "                    add_in=np.where(red_swift_removals==j)[0][0]\n",
    "                    red_swift_removals=np.delete(red_swift_removals,add_in)\n",
    "            elif type(red_swift_removals)==int and red_swift_removals==j:\n",
    "                red_swift_removals=[]\n",
    "            #I /think/ this will add the removed ones back in. Probably.\n",
    "            row_match=int(np.where(xrt_matches[:, 0]==j)[0][0])\n",
    "            redshift_xrt=np.append(redshift_xrt,[[int(j),xrt_matches[row_match,1]]],\\\n",
    "                                   axis=0)\n",
    "            redshift_stages=np.append(redshift_stages,[[int(xrt_stages[row_match,0]),\\\n",
    "                                                        int(xrt_stages[row_match,1])]],\\\n",
    "                                      axis=0)\n",
    "            break\n",
    "#         elif swift_string_2 != redshift_string_2 and i==len(second_redshifts)-1:\n",
    "#             red_swift_removals=np.append(red_swift_removals, j)\n",
    "#             break\n",
    "        else: \n",
    "            continue\n",
    "# weird_removals=list(set(red_swift_removals))\n",
    "redshift_matches=redshift_matches[1:]\n",
    "redshift_xrt=redshift_xrt[1:]\n",
    "redshift_stages=redshift_stages[1:]\n",
    "# redshift_avg_slope=redshift_avg_slope[1:]\n",
    "redshift_swift_data = edited_swift_data.drop(index=red_swift_removals)\n",
    "# print(len(edited_swift_data))\n",
    "# print(len(redshift_swift_data))\n",
    "edited_swift_data = swift_data.drop(index=removals)\n",
    "sample_1_data=edited_swift_data\n",
    "#For some reason I won't pretend to understand, creating sample 4 HERE prevents errors in \n",
    "#creating sample 3. Oy vey.\n",
    "sample_4_data=redshift_swift_data\n",
    "print(len(sample_1_data))\n",
    "print(len(sample_4_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de855a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating Sample 2##\n",
    "sample_2_data=fermi_data\n",
    "print(len(sample_2_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating Sample 3##\n",
    "##Data conversion##\n",
    "edited_indices=list(np.where(edited_swift_data.index!=0))\n",
    "t=Time(edited_swift_data.at[int(edited_swift_data.index[0]),\\\n",
    "                            '       Trig_time_UTC        '].strip(), \\\n",
    "       format='isot', scale='utc')\n",
    "gorp=t.jd; #honestly at this point I gave up on naming variables\n",
    "shoes=float(edited_swift_data.at[int(edited_swift_data.index[0]),'  RA_ground   '])\n",
    "sorks=float(edited_swift_data.at[int(edited_swift_data.index[0]),'     T90      '])\n",
    "gatorade=float(edited_swift_data.at[int(edited_swift_data.index[0]), ' Image_position_err '])\n",
    "helmet=float(edited_swift_data.at[int(edited_swift_data.index[0]),'  DEC_ground   '])\n",
    "nom=str(edited_swift_data.at[int(edited_swift_data.index[0]),'GRBname '].strip())\n",
    "for i in list(edited_swift_data.index):\n",
    "    if type(edited_swift_data.at[i,'       Trig_time_UTC        '])==str:\n",
    "        t=Time(edited_swift_data.at[i,'       Trig_time_UTC        '].strip(), \\\n",
    "               format='isot', scale='utc')\n",
    "        gorp=np.append(gorp, t.jd)\n",
    "        shoes=np.append(shoes, float(edited_swift_data.at[i,'  RA_ground   ']))\n",
    "        sorks=np.append(sorks, float(edited_swift_data.at[i,'     T90      ']))\n",
    "        gatorade=np.append(gatorade, float(edited_swift_data.at[i,' Image_position_err ']))\n",
    "        helmet=np.append(helmet, float(edited_swift_data.at[i,'  DEC_ground   ']))\n",
    "        nom=np.append(nom, str(edited_swift_data.at[i,'GRBname '].strip()))\n",
    "    else :\n",
    "        gorp=np.append(gorp, 1)\n",
    "        sorks=np.append(sorks, float(edited_swift_data.at[i,'     T90      ']))\n",
    "        shoes=np.append(shoes, float(edited_swift_data.at[i,'  RA_ground   ']))\n",
    "        gatorade=np.append(gatorade, float(edited_swift_data.at[i,' Image_position_err ']))\n",
    "        helmet=np.append(helmet, float(edited_swift_data.at[i,'  DEC_ground   ']))\n",
    "        nom=np.append(nom, str(edited_swift_data.at[i,'GRBname '].strip()))\n",
    "t0=fermi_data.at[0,\"trigger_time           \"]\n",
    "t0=re.split(\"/| |:\", t0)\n",
    "t0 = list(map(int, t0))\n",
    "t0=datetime.datetime(t0[2], t0[0], t0[1], t0[3], t0[4], t0[5], int(t0[6]))\n",
    "trail_mix = julian.to_jd(t0, fmt='jd') #honestly at this point I gave up on naming variables\n",
    "soles=fermi_data.at[0,'ra        ']\n",
    "soles=soles.split(' ')\n",
    "soles=list(map(float, soles)) \n",
    "boots=((soles[0]+(soles[1]+soles[2]/60)/60)*15)\n",
    "fabric=fermi_data.at[0,'dec      ']\n",
    "fabric=fabric.split(' ')\n",
    "fabric=list(map(float, fabric)) \n",
    "hat=(fabric[0]+(fabric[1]+fabric[2]/60)/60)\n",
    "socks=fermi_data.at[0,'t90_error']\n",
    "w0ter=fermi_data.at[0, 'error_radius']\n",
    "for i in range(1,len(fermi_data)):\n",
    "    ti83=fermi_data.at[i,\"trigger_time           \"]\n",
    "    ti83=re.split(\"/| |:\", ti83)\n",
    "    ti83 = list(map(int, ti83)) \n",
    "    ti83=datetime.datetime(ti83[2], ti83[0], ti83[1], ti83[3], ti83[4], ti83[5], \\\n",
    "                           int(ti83[6]))\n",
    "    trail_mix = np.append(trail_mix, julian.to_jd(ti83, fmt='jd'))\n",
    "    soles=fermi_data.at[i,'ra        ']\n",
    "    soles=soles.split(' ')\n",
    "    soles=list(map(float, soles)) \n",
    "    soles=((soles[0]+(soles[1]+soles[2]/60)/60)*15)\n",
    "    boots=np.append(boots, soles)\n",
    "    fabric=fermi_data.at[i,'dec      ']\n",
    "    fabric=fabric.split(' ')\n",
    "    fabric=list(map(float, fabric)) \n",
    "    fabric=(fabric[0]+(fabric[1]+fabric[2]/60)/60)\n",
    "    hat=np.append(hat, fabric)\n",
    "    socks=np.append(socks, fermi_data.at[i,'t90_error'])\n",
    "    w0ter=np.append(w0ter, fermi_data.at[i,'error_radius'])\n",
    "##match data##\n",
    "food = np.zeros((len(trail_mix),len(gorp)))\n",
    "feet_covers = np.zeros((len(trail_mix),len(gorp)))\n",
    "UV_protection = np.zeros((len(trail_mix),len(gorp)))\n",
    "k=0;\n",
    "for i in range(0, len(gorp)):\n",
    "    for j in range(0, len(trail_mix)):\n",
    "        food[j, i] = abs(trail_mix[j]-gorp[i]);\n",
    "        feet_covers[j, i] = abs(boots[j]-shoes[i]);\n",
    "        UV_protection[j, i] = abs(hat[j]-helmet[i]);\n",
    "        if food[j,i]<0.0035:\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers[j,i]<3*gatorade[i]:\n",
    "                    if UV_protection[j,i]<3*gatorade[i]:\n",
    "                        k=k+1;\n",
    "            else:\n",
    "                if feet_covers[j,i]<3*w0ter[j]:\n",
    "                    if UV_protection[j,i]<3*w0ter[j]:\n",
    "                        k=k+1;\n",
    "matches = np.zeros((k+1, 15))\n",
    "potential_matches=np.zeros((k,3))\n",
    "print(k)\n",
    "k=0;\n",
    "err=0;\n",
    "special_cases=[]\n",
    "for i in range(0, len(gorp)):\n",
    "    for j in range(0, len(trail_mix)):\n",
    "        if food[j,i]<0.0035: #time\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers[j,i]<3*gatorade[i]: #RA\n",
    "                    if UV_protection[j,i]<3*gatorade[i]: #dec\n",
    "                        potential_matches[k,0]=food[j,i]\n",
    "                        potential_matches[k,1]=w0ter[j]\n",
    "                        potential_matches[k,2]=gatorade[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        matches[k,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        matches[k,1] = j\n",
    "                        matches[k,2] = edited_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade[i] != 0:\n",
    "                            matches[k,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #alpha\n",
    "                            matches[k,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #beta\n",
    "                        else:\n",
    "                            matches[k,3]='NaN'\n",
    "                            matches[k,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        matches[k,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        matches[k,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        matches[k,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        matches[k,8] = fermi_data.at[j,'fluence   ']\n",
    "                        matches[k,9] = fermi_data.at[j,'fluence_error']\n",
    "                        if swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,10] = swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                               ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,10] = 0\n",
    "                        if swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,11] =  swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,11] = 0\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            matches[k,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            matches[k,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            matches[k,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            matches[k,12] = 4\n",
    "                        else:\n",
    "                            matches[k,12] = 0\n",
    "                        #pdb.set_trace()\n",
    "                        xrt_xcall=np.where(xrt_matches[:,0]==\\\n",
    "                                                 edited_swift_data.index[i-1])[0][0]\n",
    "                        matches[k,13]=int(xrt_matches[xrt_xcall, 1])\n",
    "                        matches[k,14] = int(xrt_stages[i-1,1])\n",
    "#     #                     matches[k, 11]=xrt_data.at[xrt_call,\\\n",
    "#     #                                         'XRT Early Flux (0.3-10 keV) [10^-11 erg/cm^2/s]']\n",
    "#     #                     print(i-1)\n",
    "#     #                     print(xrt_call)\n",
    "#                         if int(xrt_stages[i-1,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         elif int(xrt_stages[i-1,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "#     #                     print(fermi_data.at[j,\"name        \"])\n",
    "#     #                     print(flux_recall)\n",
    "#     #                     print(more_xrt_data[flux_recall][xrt_call])\n",
    "#                         matches[k, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             matches[k,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             matches[k,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             matches[k,14]=headphones[0]\n",
    "#                             matches[k,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             matches[k, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             matches[k, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         matches[k,16]=xrt_avg_slope[xrt_xcall, 1]\n",
    "                        k=k+1\n",
    "            else:\n",
    "                if feet_covers[j,i]<3*w0ter[j]: #RA\n",
    "                    if UV_protection[j,i]<3*w0ter[j]: #dec\n",
    "                        special_cases=np.append(special_cases,fermi_data.at[j,\"name        \"])\n",
    "            \n",
    "                        potential_matches[k,0]=food[j,i]\n",
    "                        potential_matches[k,1]=w0ter[j]\n",
    "                        potential_matches[k,2]=gatorade[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        matches[k,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        matches[k,1] = j\n",
    "                        matches[k,2] = edited_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade[i] != 0:\n",
    "                            matches[k,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #alpha\n",
    "                            matches[k,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes[i], sigma=gatorade[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet[i], sigma=gatorade[i])) #beta\n",
    "                        else:\n",
    "                            matches[k,3]='NaN'\n",
    "                            matches[k,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        matches[k,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        matches[k,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        matches[k,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        matches[k,8] = fermi_data.at[j,'fluence   ']\n",
    "                        matches[k,9] = fermi_data.at[j,'fluence_error']\n",
    "                        if swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,10] = swift_fluxes.at[edited_swift_data.index[i],\\\n",
    "                                                               ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,10] = 0\n",
    "                        if swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev '] != ' N/A ':\n",
    "                            matches[k,11] = swift_fluences.at[edited_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        else:\n",
    "                            matches[k,11] = 0\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            matches[k,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            matches[k,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            matches[k,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            matches[k,12] = 4\n",
    "                        else:\n",
    "                            matches[k,12] = 0\n",
    "                        xrt_xcall=np.where(xrt_matches[:,0]==\\\n",
    "                                                 edited_swift_data.index[i-1])[0][0]\n",
    "                        matches[k,13]=int(xrt_matches[xrt_xcall, 1])\n",
    "                        matches[k,14] = int(xrt_stages[i-1,1])\n",
    "#                         if int(xrt_stages[i-1,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         elif int(xrt_stages[i-1,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(xrt_stages[i-1,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                     format(int(xrt_stages[i-1,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "#                         matches[k, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             matches[k,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             matches[k,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             matches[k,14]=headphones[0]\n",
    "#                             matches[k,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             matches[k, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             matches[k, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         matches[k,16]=xrt_avg_slope[xrt_xcall, 1]\n",
    "                        k=k+1\n",
    "regular_matches=pd.DataFrame(matches, columns=['name', 'Fermi row', 'Swift row',\\\n",
    "                                               'Type I error', \\\n",
    "                                       'Type II error', 't90', 't90_error', 'GBM flux', \\\n",
    "                                       'GBM fluence', 'Fluence error',\\\n",
    "                                               'BAT flux', 'BAT fluence',\\\n",
    "                                               'Spectral Model', 'XRT row', \\\n",
    "                                               'Plateau Stage'])#,\\\n",
    "#                                                '\"Plateau\" X-Ray Flux', \\\n",
    "#                                                \"Pre-X-ray Flux Change\", \\\n",
    "#                                                \"Post-X-ray Flux Change\"])\n",
    "regular_matches=regular_matches[:-1]\n",
    "sample_3_data=regular_matches\n",
    "print(special_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating Sample 6##\n",
    "##Data conversion fo the redshift data##\n",
    "start_index=redshift_swift_data.index[0]\n",
    "t2=Time(redshift_swift_data.at[start_index,'       Trig_time_UTC        '].strip(), \\\n",
    "               format='isot', scale='utc')\n",
    "gorp2=t2.jd; #honestly at this point I gave up on naming variables\n",
    "shoes2=float(redshift_swift_data.at[start_index,'  RA_ground   '])\n",
    "sorks2=float(redshift_swift_data.at[start_index,'     T90      '])\n",
    "gatorade2=float(redshift_swift_data.at[start_index, ' Image_position_err '])\n",
    "helmet2=float(redshift_swift_data.at[start_index,'  DEC_ground   '])\n",
    "nom2=str(redshift_swift_data.at[start_index,'GRBname '].strip())\n",
    "for i in list(redshift_swift_data.index):\n",
    "    if i !=redshift_swift_data.index[0]:\n",
    "        if type(redshift_swift_data.at[i,'       Trig_time_UTC        '])==str:\n",
    "            t2=Time(redshift_swift_data.at[i,'       Trig_time_UTC        '].strip(), \\\n",
    "               format='isot', scale='utc')\n",
    "            gorp2=np.append(gorp2, t2.jd)\n",
    "            shoes2=np.append(shoes2, float(redshift_swift_data.at[i,'  RA_ground   ']))\n",
    "            sorks2=np.append(sorks2, float(redshift_swift_data.at[i,'     T90      ']))\n",
    "            gatorade2=np.append(gatorade2, \\\n",
    "                            float(redshift_swift_data.at[i,' Image_position_err ']))\n",
    "            helmet2=np.append(helmet2, float(redshift_swift_data.at[i,'  DEC_ground   ']))\n",
    "            nom2=np.append(nom2, str(redshift_swift_data.at[i,'GRBname '].strip()))\n",
    "        else:\n",
    "            gorp2=np.append(gorp2, 1)\n",
    "            sorks2=np.append(sorks2, float(redshift_swift_data.at[i,'     T90      ']))\n",
    "            shoes2=np.append(shoes2, float(redshift_swift_data.at[i,'  RA_ground   ']))\n",
    "            gatorade2=np.append(gatorade2, \\\n",
    "                            float(redshift_swift_data.at[i,' Image_position_err ']))\n",
    "            helmet2=np.append(helmet2, float(redshift_swift_data.at[i,'  DEC_ground   ']))\n",
    "            nom2=np.append(nom2, str(redshift_swift_data.at[i,'GRBname '].strip()))\n",
    "        #Honestly, all the Fermi stuff already existed, so I deleted it\n",
    "    else:\n",
    "        continue\n",
    "##Match the Redshift Data too ##\n",
    "food_2 = np.zeros((len(trail_mix),len(gorp2)))\n",
    "feet_covers_2 = np.zeros((len(trail_mix),len(gorp2)))\n",
    "UV_protection_2 = np.zeros((len(trail_mix),len(gorp2)))\n",
    "l=0;\n",
    "for i in range(0, len(gorp2)):\n",
    "    for j in range(0, len(trail_mix)):\n",
    "        food_2[j, i] = abs(trail_mix[j]-gorp2[i]);\n",
    "        feet_covers_2[j, i] = abs(boots[j]-shoes2[i]);\n",
    "        UV_protection_2[j, i] = abs(hat[j]-helmet2[i]);\n",
    "        if food_2[j,i]<0.0035:\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers_2[j,i]<3*gatorade2[i]:\n",
    "                    if UV_protection_2[j,i]<3*gatorade2[i]:\n",
    "                        l=l+1;\n",
    "            else:\n",
    "                if feet_covers[j,i]<3*w0ter[j]:\n",
    "                    if UV_protection[j,i]<3*w0ter[j]:\n",
    "                        l=l+1;\n",
    "z_matches = np.zeros((l+1, 16))\n",
    "z_potential_matches=np.zeros((l+1,3))\n",
    "print(l)\n",
    "l=0;\n",
    "err=0;\n",
    "special_cases=[]\n",
    "for i in range(0, len(gorp2)-1):\n",
    "    for j in range(0, len(trail_mix)-1):\n",
    "        if food_2[j,i]<0.0035: #time\n",
    "            if w0ter[j]<0.1:\n",
    "                if feet_covers_2[j,i]<3*gatorade2[i]: #RA\n",
    "                    if UV_protection_2[j,i]<3*gatorade2[i]: #dec\n",
    "                        z_potential_matches[l,0]=food_2[j,i]\n",
    "                        z_potential_matches[l,1]=w0ter[j]\n",
    "                        z_potential_matches[l,2]=gatorade2[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        z_matches[l,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        z_matches[l,1] = j\n",
    "                        z_matches[l,2] = redshift_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade2[i] != 0:\n",
    "                            z_matches[l,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #alpha\n",
    "                            z_matches[l,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #beta\n",
    "                        else:\n",
    "                            z_matches[l,3]='NaN'\n",
    "                            z_matches[l,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        z_matches[l,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        z_matches[l,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        z_matches[l,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        z_matches[l,8] = fermi_data.at[j,'fluence   ']\n",
    "                        z_matches[l,9] = fermi_data.at[j,'fluence_error']\n",
    "                        if swift_fluxes.at[redshift_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev '] != ' N/A ':\n",
    "                            z_matches[l,10] = swift_fluxes.at[redshift_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev ']\n",
    "                        else:\n",
    "                            z_matches[l,10] = 0\n",
    "                        if swift_fluences.at[redshift_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev '] != ' N/A ':\n",
    "                            z_matches[l,11] = swift_fluences.at[redshift_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        else:\n",
    "                            z_matches[l, 11] = 0\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            z_matches[l,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            z_matches[l,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            z_matches[l,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            z_matches[l,12] = 4\n",
    "                        else:\n",
    "                            z_matches[l,12] = 0\n",
    "                        z_matches[l,13] = int(redshift_xrt[i, 1])\n",
    "                        z_matches[l,14] = int(redshift_stages[i,1])\n",
    "#                         if int(redshift_stages[i,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         elif int(redshift_stages[i,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "#                         z_matches[l, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             z_matches[l,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             z_matches[l,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             z_matches[l,14]=headphones[0]\n",
    "#                             z_matches[l,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             z_matches[l, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             z_matches[l, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         z_matches[l,16]=redshift_avg_slope[i, 1]\n",
    "                        if len(np.where(redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 0\n",
    "                        elif len(np.where(other_redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(other_redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 1\n",
    "                        l=l+1;\n",
    "            else:\n",
    "                if feet_covers_2[j,i]<3*w0ter[j]: #RA\n",
    "                    if UV_protection_2[j,i]<3*w0ter[j]: #dec\n",
    "                        special_cases=np.append(special_cases,fermi_data.at[j,\"name        \"])\n",
    "                        z_potential_matches[l,0]=food_2[j,i]\n",
    "                        z_potential_matches[l,1]=w0ter[j]\n",
    "                        z_potential_matches[l,2]=gatorade2[i]\n",
    "                        name=fermi_data.at[j,\"name        \"]\n",
    "                        z_matches[l,0] = int(name[3]+name[4]+name[5]+name[6]+\\\n",
    "                                           name[7]+name[8]+name[9]+name[10]+name[11])\n",
    "                        z_matches[l,1] = j\n",
    "                        z_matches[l,2] = redshift_swift_data.index[i]\n",
    "                        if w0ter[j] != 0 and gatorade2[i] != 0:\n",
    "                            z_matches[l,3] = 1-NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #alpha\n",
    "                            z_matches[l,4] = NormalDist(mu=boots[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=shoes2[i], sigma=gatorade2[i]))*\\\n",
    "                                        NormalDist(mu=hat[j], sigma=w0ter[j]).overlap(\\\n",
    "                                        NormalDist(mu=helmet2[i], sigma=gatorade2[i])) #beta\n",
    "                        else:\n",
    "                            z_matches[l,3]='NaN'\n",
    "                            z_matches[l,4]='NaN'\n",
    "                            err=err+1;\n",
    "                        z_matches[l,5] = fermi_data.at[j,\"t90     \"]\n",
    "                        z_matches[l,6] = fermi_data.at[j,\"t90_error\"]\n",
    "                        z_matches[l,7] = fermi_data.at[j,'flux_256 ']\n",
    "                        z_matches[l,8] = fermi_data.at[j,'fluence   ']\n",
    "                        z_matches[l,9] = fermi_data.at[j,'fluence_error']\n",
    "                        z_matches[l,10] = swift_fluxes.at[redshift_swift_data.index[i],\\\n",
    "                                                           ' 15_350kev ']\n",
    "                        z_matches[l,11] = swift_fluences.at[redshift_swift_data.index[i],\\\n",
    "                                                             ' 15_350kev ']\n",
    "                        if fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_plaw              ':\n",
    "                            z_matches[l,12] = 1\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_band              ':\n",
    "                            z_matches[l,12] = 2\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_comp              ':\n",
    "                            z_matches[l,12] = 3\n",
    "                        elif fermi_data.at[j,'flnc_best_fitting_model']==\\\n",
    "                        'flnc_sbpl              ':\n",
    "                            z_matches[l,12] = 4\n",
    "                        else:\n",
    "                            z_matches[l,12] = 0\n",
    "#                         xrt_xcall=np.where(redshift_xrt[:,0]==i)[0][0]\n",
    "                        z_matches[l,13]=int(redshift_xrt[i, 1])\n",
    "                        z_matches[l,14] = int(redshift_stages[i,1])\n",
    "    #                     matches[k, 11]=xrt_data.at[xrt_call,\\\n",
    "    #                                         'XRT Early Flux (0.3-10 keV) [10^-11 erg/cm^2/s]']\n",
    "    #                     print(i)\n",
    "    #                     print(xrt_call)\n",
    "#                         if int(redshift_stages[i,0])==0:\n",
    "#                             flux_recall=' Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (pc) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         elif int(redshift_stages[i,0])==1:\n",
    "#                             flux_recall=' Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                             flux_change=' D_Obs Flux_{} (wt) '.\\\n",
    "#                                 format(int(redshift_stages[i,1]))\n",
    "#                         else:\n",
    "#                             print(\"error, this burst ({}) didn't get an assigned flux.\").\\\n",
    "#                             format(fermi_data.at[j,\"name        \"])\n",
    "    #                     print(fermi_data.at[j,\"name        \"])\n",
    "    #                     print(redshift_swift_data.at[redshift_swift_data.index[i], 'GRBname '])\n",
    "    #                     print(flux_recall)\n",
    "    #                     print(more_xrt_data[flux_recall][xrt_call])\n",
    "#                         z_matches[l, 13]=more_xrt_data[flux_recall][xrt_call]\n",
    "#                         if more_xrt_data[flux_change][xrt_call]==' , ':\n",
    "#                             z_matches[l,14]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             z_matches[l,15]=0.34*float(more_xrt_data[flux_recall][xrt_call])\n",
    "#                             #this is about one standard deviation\n",
    "#                         elif ',' in str(more_xrt_data[flux_change][xrt_call]):\n",
    "#                             dual_input=re.split(\",\", str(more_xrt_data[flux_change][xrt_call])\\\n",
    "#                                                 .strip())\n",
    "#                             headphones = list(map(float, dual_input))\n",
    "#                             z_matches[l,14]=headphones[0]\n",
    "#                             z_matches[l,15]=headphones[1]\n",
    "#                             #I originally only left room for one value. That was a mistake.\n",
    "#                         else:\n",
    "#                             z_matches[l, 14]=more_xrt_data[flux_change][xrt_call]\n",
    "#                             z_matches[l, 15]=more_xrt_data[flux_change][xrt_call]\n",
    "#                         z_matches[l,16]=redshift_avg_slope[i, 1]\n",
    "    #                     z_matches[l,15]=max(more_xrt_data[' Ave_obs_flux_WT '][xrt_call],\\\n",
    "    #                                       more_xrt_data[' Ave_obs_flux_PC '][xrt_call])\n",
    "    #                     avg_flux=np.where([more_xrt_data[' Ave_obs_flux_WT '][xrt_call],\\\n",
    "    #                                       more_xrt_data[' Ave_obs_flux_PC '][xrt_call]]==\\\n",
    "    #                             max(more_xrt_data[' Ave_obs_flux_WT '][xrt_call],\\\n",
    "    #                                       more_xrt_data[' Ave_obs_flux_PC '][xrt_call]))\n",
    "    #                     if avg_flux==0:\n",
    "    #                         z_matches[l, 16]=more_xrt_data[' d_Ave_obs_flux_WT '][xrt_call]\n",
    "    #                     elif avg_flux==1:\n",
    "    #                         z_matches[l, 16]=more_xrt_data[' d_Ave_obs_flux_PC '][xrt_call]\n",
    "                        if len(np.where(redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 0\n",
    "                        elif len(np.where(other_redshift_matches[:,1]==\\\n",
    "                                        redshift_swift_data.index[i])[0])>0:\n",
    "                            redshift_recall=np.where(other_redshift_matches[:,1]==\\\n",
    "                                                     redshift_swift_data.index[i])[0][0]\n",
    "                            redshift_call=redshift_matches[redshift_recall, 0]\n",
    "                            z_matches[l,15] = float(swift_redshifts.at[redshift_call, ' z ']\\\n",
    "                                                .strip().replace('(?)', '')\\\n",
    "                                                .replace('?', '').replace('<', '').\\\n",
    "                                               replace('>', ''))\n",
    "                            #z_matches[l, 15] = 1\n",
    "                        l=l+1;\n",
    "redshifted_matches=pd.DataFrame(z_matches, columns=['name', 'Fermi row', 'Swift row', \\\n",
    "                                                    'Type I error', \\\n",
    "                                       'Type II error', 't90', 't90_error', 'GBM flux', \\\n",
    "                                       'GBM fluence', 'Fluence error',\\\n",
    "                                                    'BAT flux', 'BAT fluence',\\\n",
    "                                                    'Spectral Model', 'XRT row', \\\n",
    "                                                    'Plateau Stage',\\\n",
    "#                                                '\"Plateau\" X-Ray Flux',\\\n",
    "#                                                \"Pre-X-ray Flux Change\", \\\n",
    "#                                                \"Post-X-ray Flux Change\",\\\n",
    "                                                    'Likely Redshift'])\n",
    "redshifted_matches=redshifted_matches[:-1]\n",
    "sample_6_data=redshifted_matches\n",
    "print(special_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4cded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hypothesis 2a##\n",
    "spectral_mask=np.isin(sample_6_data['Spectral Model'], 0.0)\n",
    "spectral_sample_6_data=sample_6_data[~spectral_mask]\n",
    "#not really \"necessary\", but I find it saves me a little time\n",
    "Initial_2a_Data=np.zeros((len(spectral_sample_6_data.index),7))\n",
    "speed_light=3e10 #now in cm/s\n",
    "H_0=70*10**5/(3.086e24)\n",
    "nu=10**(18)\n",
    "j=0\n",
    "for i in spectral_sample_6_data.index:\n",
    "    rs=spectral_sample_6_data['Likely Redshift'][i]\n",
    "    flu=spectral_sample_6_data['GBM fluence'][i]\n",
    "    flu_err=sample_2_data.at[spectral_sample_6_data.at[i, 'Fermi row'], 'fluence_error']\n",
    "    d_lum=((2*speed_light)/H_0)*(1-np.sqrt(1/(1+rs)))*(1+rs)\n",
    "    ghostie=spectral_sample_6_data['Spectral Model'][i]\n",
    "    #get it, ghostie becuase it's the SPEC-trum. I guess code isn't the time to make jokes.\n",
    "    fermi_placement= spectral_sample_6_data['Fermi row'][i]\n",
    "    #at least this one is descriptive\n",
    "    k=Fermi_k_func(sample_2_data, ghostie, fermi_placement, rs)\n",
    "    E_iso=4*np.pi*((d_lum)**2)*flu*k/(1+rs)\n",
    "    Initial_2a_Data[j, 0]= spectral_sample_6_data['name'][i]\n",
    "    Initial_2a_Data[j, 1]= E_iso\n",
    "    E_iso_err=4*np.pi*((d_lum)**2)*flu_err*k/(1+rs)\n",
    "    Initial_2a_Data[j, 2]=E_iso_err\n",
    "    backstop=int(spectral_sample_6_data['Plateau Stage'][i])\n",
    "    row=spectral_sample_6_data['XRT row'][i]\n",
    "    model_selector=more_xrt_data[' #breaks '][row]\n",
    "    if model_selector>=1:\n",
    "        break_1=int(float(more_xrt_data[' break_1 '][row]))\n",
    "        split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_1 '].strip())\n",
    "        if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "            split_err= list(map(float, split_err))\n",
    "            err_break_1=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "        elif split_err[0] !='':\n",
    "            err_break_1=float(split_err[0])\n",
    "        elif split_err[1] != '':\n",
    "            err_break_1=float(split_err[1])\n",
    "        else:\n",
    "            err_break_1=0\n",
    "        power_1=-float(more_xrt_data[' alpha_1 '][row])\n",
    "        power_2=-float(more_xrt_data[' alpha_2 '][row])\n",
    "        if backstop==1:\n",
    "            front=0\n",
    "            error_front=0\n",
    "            back=break_1\n",
    "            error_back=float(err_break_1)\n",
    "        if model_selector>=2:\n",
    "            break_2=int(float(more_xrt_data[' break_2 '][row]))\n",
    "            split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_2 '].strip())\n",
    "            if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "                split_err= list(map(float, split_err))\n",
    "                err_break_2=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "            elif split_err[0] !='':\n",
    "                err_break_2=float(split_err[0])\n",
    "            elif split_err[1] != '':\n",
    "                err_break_2=float(split_err[1])\n",
    "            else:\n",
    "                err_break_2=0\n",
    "            power_3=-float(more_xrt_data[' alpha_3 '][row])\n",
    "            if backstop==2:\n",
    "                front=break_1\n",
    "                error_front=float(err_break_1)\n",
    "                back=break_2\n",
    "                error_back=float(err_break_2)\n",
    "            if model_selector>=3:\n",
    "                break_3=int(float(more_xrt_data[' break_3 '][row]))\n",
    "                split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_3 '].strip())\n",
    "                if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "                    split_err= list(map(float, split_err))\n",
    "                    err_break_3=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "                elif split_err[0] !='':\n",
    "                    err_break_3=float(split_err[0])\n",
    "                elif split_err[1] != '':\n",
    "                    err_break_3=float(split_err[1])\n",
    "                else:\n",
    "                    err_break_3=0\n",
    "                power_4=-float(more_xrt_data[' alpha_4 '][row])\n",
    "                if backstop==3:\n",
    "                    front=break_2\n",
    "                    error_front=float(err_break_2)\n",
    "                    back=break_3\n",
    "                    error_back=float(err_break_3)\n",
    "                if model_selector>=4:\n",
    "                    break_4=int(float(more_xrt_data[' break_4 '][row]))\n",
    "                    split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_4 '].strip())\n",
    "                    if split_err and split_err[0] !='' and split_err[1] != '':\n",
    "                        split_err= list(map(float, split_err))\n",
    "                        err_break_4=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "                    elif split_err[0] !='':\n",
    "                        err_break_4=float(split_err[0])\n",
    "                    elif split_err[1] != '':\n",
    "                        err_break_4=float(split_err[1])\n",
    "                    else:\n",
    "                        err_break_4=0\n",
    "                    power_5=-float(more_xrt_data[' alpha_5 '][row])\n",
    "                    if backstop==4:\n",
    "                        front=break_3\n",
    "                        error_front=float(err_break_3)\n",
    "                        back=break_4\n",
    "                        error_back=float(err_break_4)\n",
    "                    if model_selector==5:\n",
    "                        break_5=int(float(more_xrt_data[' break_5 '][row]))\n",
    "                        split_err=re.split(\",\", more_xrt_data.at[i, ' D_break_5 '].strip())\n",
    "                        if split_err and split_err[0] !='' and split[1] != '':\n",
    "                            split_err= list(map(float, split_err))\n",
    "                            err_break_5=np.mean([abs(split_err[0]), abs(split_err[1])])\n",
    "                        elif split_err[0] !='':\n",
    "                            err_break_5=float(split_err[0])\n",
    "                        elif split_err[1] != '':\n",
    "                            err_break_5=float(split_err[1])\n",
    "                        else:\n",
    "                            err_break_5=0\n",
    "                        power_6=-float(more_xrt_data[' alpha_6 '][row]) \n",
    "                        if backstop==5:\n",
    "                            front=break_4\n",
    "                            error_back=float(err_break_4)\n",
    "                            back=break_5\n",
    "                            error_back=float(err_break_5)\n",
    "                        initial_value=quintuply_broken_PL(1, break_1, break_2, break_3, \\\n",
    "                                    break_4, break_5, power_1, power_2, power_3, power_4, \\\n",
    "                                        power_5, power_6, 0, 11*60*60)\n",
    "                        Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                         0.01)[0]\n",
    "                        if abs(quintuply_broken_PL(Q, break_1, break_2, break_3, break_4, \\\n",
    "                                break_5, power_1, power_2, power_3, power_4, power_5, power_6, \\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                            AG_fluence=integrate.quad(lambda t: quintuply_broken_PL(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, break_5, power_1, \\\n",
    "                                power_2, power_3, power_4, power_5, power_6, 0, t), \\\n",
    "                                                      front, back)[0]\n",
    "                            AG_fluence_err=np.sqrt((\\\n",
    "                                quintuply_broken_PL_derivative(Q, break_1, break_2, break_3,\\\n",
    "                                break_4, break_5, power_1, power_2, power_3, power_4, power_5, \\\n",
    "                                power_6, 0, front)*error_front)**2+(\\\n",
    "                                quintuply_broken_PL_derivative(Q, break_1, break_2, break_3,\\\n",
    "                                break_4, break_5, power_1, power_2, power_3, power_4, power_5, \\\n",
    "                                power_6, 0, back)*error_back)**2)\n",
    "                    else:\n",
    "                        initial_value=quadruply_broken_PL(1, break_1, break_2, break_3, break_4, \\\n",
    "                                             power_1, power_2, power_3, power_4, power_5, \\\n",
    "                                             0, 11*60*60)\n",
    "                        Q=fsolve(lambda A: A*initial_value-float(\\\n",
    "                                    more_xrt_data[' Flux_11 '][row]),0.01)[0]\n",
    "                        if abs(quadruply_broken_PL(Q, break_1, break_2, break_3, break_4, \\\n",
    "                            power_1, power_2, power_3, power_4, power_5,\\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                            AG_fluence=integrate.quad(lambda t: quadruply_broken_PL(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, power_1, power_2, \\\n",
    "                                power_3, power_4, power_5, 0, t), front, back)[0]\n",
    "                            AG_fluence_err=np.sqrt((quadruply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, power_1, power_2, \\\n",
    "                                power_3, power_4, power_5, 0, front)*error_front)**2+(\\\n",
    "                                quadruply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, break_4, power_1, power_2, \\\n",
    "                                power_3, power_4, power_5, 0, back)*error_back)**2)\n",
    "                else:\n",
    "                    initial_value=triply_broken_PL(1, break_1, break_2, break_3, \\\n",
    "                                             power_1, power_2, power_3, power_4, \\\n",
    "                                             0, 11*60*60)\n",
    "                    Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                     0.01)[0]\n",
    "                    if abs(triply_broken_PL(Q, break_1, break_2, break_3, \\\n",
    "                            power_1, power_2, power_3, power_4,\\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                        AG_fluence=integrate.quad(lambda t: triply_broken_PL(Q, \\\n",
    "                                break_1, break_2, break_3, power_1, power_2, \\\n",
    "                                power_3, power_4, 0, t), front, back)[0]\n",
    "                        AG_fluence_err=np.sqrt((triply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, power_1, power_2, \\\n",
    "                                power_3, power_4, 0, front)*error_front)**2+(\\\n",
    "                                triply_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, break_3, power_1, power_2, \\\n",
    "                                power_3, power_4, 0, back)*error_back)**2)\n",
    "            else:\n",
    "                initial_value=doubly_broken_PL(1, break_1, break_2, \\\n",
    "                                             power_1, power_2, power_3, \\\n",
    "                                             0, 11*60*60)\n",
    "                Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                     0.01)[0]\n",
    "                if abs(doubly_broken_PL(Q, break_1, break_2, power_1, power_2, power_3, \\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                    AG_fluence=integrate.quad(lambda t: doubly_broken_PL(Q, \\\n",
    "                                break_1, break_2, power_1, power_2, \\\n",
    "                                power_3, 0, t), front, back)[0]\n",
    "                    AG_fluence_err=np.sqrt((doubly_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, power_1, power_2, \\\n",
    "                                power_3, 0, front)*error_front)**2+(\\\n",
    "                                doubly_broken_PL_derivative(Q, \\\n",
    "                                break_1, break_2, power_1, power_2, \\\n",
    "                                power_3, 0, back)*error_back)**2)\n",
    "        else:\n",
    "            initial_value=singly_broken_PL(1, break_1, power_1, power_2, 0, 11*60*60)\n",
    "            Q=fsolve(lambda A: A*initial_value-float(more_xrt_data[' Flux_11 '][row]),\\\n",
    "                     0.01)[0]\n",
    "            if abs(singly_broken_PL(Q, break_1, power_1, power_2, \\\n",
    "                            0, 24*60*60)-float(more_xrt_data[' Flux_24 '][row]))/\\\n",
    "                        (float(more_xrt_data[' Flux_24 '][row]))<0.05:\n",
    "                AG_fluence=integrate.quad(lambda t: singly_broken_PL(Q, \\\n",
    "                                break_1, power_1, power_2, 0, t), front, back)[0]\n",
    "                AG_fluence_err=np.sqrt(\\\n",
    "                                (singly_broken_PL_derivative(1, break_1, power_1, power_2,\\\n",
    "                                0, front)*error_front**2\\\n",
    "                                 +(singly_broken_PL_derivative(1, break_1, power_1, \\\n",
    "                                power_2, 0, back)*error_back)**2))\n",
    "    else:\n",
    "        AG_fluence=np.NaN\n",
    "    if len(np.where(spectral_sample_6_data['name'][i]==\\\n",
    "                       average_decay_data['Fermi name'])[0])>0:\n",
    "        decay_pos=int(np.where(spectral_sample_6_data['name'][i]==\\\n",
    "                           average_decay_data['Fermi name'])[0][0])\n",
    "    else:\n",
    "        decay_pos=np.NaN\n",
    "    AG_k=XRT_k_func(average_decay_data, decay_pos, rs)\n",
    "    AG_E_iso=4*np.pi*((d_lum)**2)*AG_fluence*AG_k/(1+rs)\n",
    "    AG_E_iso_err=4*np.pi*((d_lum)**2)*AG_fluence_err*AG_k/(1+rs)\n",
    "    Initial_2a_Data[j, 3]= AG_E_iso\n",
    "    Initial_2a_Data[j, 4]= AG_E_iso_err\n",
    "    Initial_2a_Data[j, 5]=spectral_sample_6_data['t90'][i]\n",
    "    if average_decay_data['nuFnu0'][decay_pos] != 0:\n",
    "        nFn=average_decay_data['nuFnu0'][decay_pos]\n",
    "    elif average_decay_data['nuFnu1'][decay_pos] != 0:\n",
    "        nFn=average_decay_data['nuFnu1'][decay_pos]\n",
    "    else:\n",
    "        nFn=np.NaN\n",
    "    beta_stage=int(spectral_sample_6_data['Plateau Stage'][i])\n",
    "    beta_string=' Gamma_{} (pc) '.format(beta_stage)\n",
    "    if weird_xrt_data.at[0, beta_string] != ' N/A ':\n",
    "        beta=(abs(float(weird_xrt_data.at[0, beta_string])-1))\n",
    "    elif weird_xrt_data.at[0, ' Gamma_{} (wt) '.format(beta_stage)]\\\n",
    "    !=' N/A ':\n",
    "        beta_string=' Gamma_{} (wt) '.format(beta_stage)\n",
    "        beta=(abs(float(weird_xrt_data.at[0, beta_string])-1))\n",
    "    else: \n",
    "        beta=np.NaN\n",
    "    time_string=' break_{} '.format(beta_stage-1)\n",
    "    # print(d_lum)\n",
    "    if time_string==' break_0 ':\n",
    "        time=0\n",
    "    elif more_xrt_data[time_string][row] != ' N/A ':\n",
    "        time=int(float(more_xrt_data[time_string][row]))\n",
    "    else:\n",
    "        time=np.NaN\n",
    "    E_k=kinetic_energy(nFn, beta, d_lum, rs, time, nu)\n",
    "    if E_k !=0:\n",
    "        eta=efficiency(E_k*1e52, E_iso)\n",
    "    else:\n",
    "        eta=np.NaN\n",
    "    Initial_2a_Data[j, 6]=eta\n",
    "    j=j+1\n",
    "Test_2a_Data=pd.DataFrame(Initial_2a_Data, columns=[\"Name\", \"Prompt E_iso\", \"Prompt_E_err\",\\\n",
    "                                                 \"Plateau E_iso\", \"Plat_E_err\", \"t90\",\\\n",
    "                                                    \"Efficiency\"])\n",
    "# outliers_mask=np.isin(Test_2a_Data[\"Name\"], \\\n",
    "#                 (150101641.0))\n",
    "No_Out_Test_2a_Data=Test_2a_Data\n",
    "short_mask=np.where(No_Out_Test_2a_Data[\"t90\"]<=2, True, False)\n",
    "Short_Test_2a_Data=No_Out_Test_2a_Data[short_mask]\n",
    "long_mask=np.where(No_Out_Test_2a_Data[\"t90\"]>2, True, False)\n",
    "Long_Test_2a_Data=No_Out_Test_2a_Data[long_mask]\n",
    "coefficients = np.polyfit(np.log10(No_Out_Test_2a_Data[\"Prompt E_iso\"]), \\\n",
    "                          np.log10(abs(No_Out_Test_2a_Data[\"Plateau E_iso\"])), 1)\n",
    "polynomial = np.poly1d(coefficients)\n",
    "log10_y_fit = polynomial(np.log10(No_Out_Test_2a_Data[\"Prompt E_iso\"]))\n",
    "plt.plot(Long_Test_2a_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Long_Test_2a_Data[\"Plateau E_iso\"]), marker=\"*\", ls='none')\n",
    "plt.plot(Short_Test_2a_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Short_Test_2a_Data[\"Plateau E_iso\"]), marker=\"o\", ls='none')\n",
    "plt.plot(No_Out_Test_2a_Data[\"Prompt E_iso\"], 10**log10_y_fit, '--')\n",
    "plt.legend(['Long GRBs', 'Short GRBs'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='x', colors='0.8')\n",
    "plt.tick_params(axis='y', colors='0.8')\n",
    "plt.xlabel(r\"Prompt Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.ylabel(r\"Plateau Afterglow Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.show()\n",
    "sm_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Short Mergers\"])\n",
    "lm_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Long Mergers\"])\n",
    "sc_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Short Collapsars\"])\n",
    "lc_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Long Collapsars\"])\n",
    "exo_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Potentially Exotic\"])\n",
    "iso_mask=np.isin(No_Out_Test_2a_Data['Name'], \\\n",
    "                Overlap_Precursors[\"Galactic Detected\"])\n",
    "Short_Test_2ab_Data=No_Out_Test_2a_Data[sm_mask|lm_mask|iso_mask]\n",
    "Long_Test_2ab_Data=No_Out_Test_2a_Data[sc_mask|lc_mask]\n",
    "Exotic_Test_2ab_Data=No_Out_Test_2a_Data[exo_mask]\n",
    "Unknown_Test_2ab_Data=No_Out_Test_2a_Data[~(lm_mask|lc_mask|sm_mask|sc_mask|exo_mask|iso_mask)]\n",
    "plt.plot(Long_Test_2ab_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Long_Test_2ab_Data[\"Plateau E_iso\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Short_Test_2ab_Data[\"Prompt Luminosity\"], \\\n",
    "#          abs(Short_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "# plt.plot(Exotic_Test_1b_Data[\"Prompt Luminosity\"], \\\n",
    "#          abs(Exotic_Test_1b_Data[\"Avg. Afterglow Decay Rate\"]), marker=\"o\", ls='none')\n",
    "plt.plot(Unknown_Test_2ab_Data[\"Prompt E_iso\"], \\\n",
    "         abs(Unknown_Test_2ab_Data[\"Plateau E_iso\"]), marker=\"*\", ls='none')\n",
    "plt.plot(No_Out_Test_2a_Data[\"Prompt E_iso\"], 10**log10_y_fit, '--')\n",
    "plt.legend(['Collapsar GRBs', 'Unknown Progenitor'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='x', colors='0.8')\n",
    "plt.tick_params(axis='y', colors='0.8')\n",
    "plt.xlabel(r\"Prompt Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.ylabel(r\"Plateau Afterglow Isotropic Energy (erg)\", color=\"0.8\")\n",
    "plt.show()\n",
    "plt.plot(Long_Test_2ab_Data['t90'], \\\n",
    "         abs(Long_Test_2ab_Data['Efficiency']), marker=\"o\", ls='none')\n",
    "plt.plot(Unknown_Test_2ab_Data['t90'], \\\n",
    "         abs(Unknown_Test_2ab_Data['Efficiency']), marker=\"*\", ls='none')\n",
    "plt.legend(['Collapsar GRBs', 'Unknown Progenitor'])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.tick_params(axis='x', colors='0.8')\n",
    "plt.tick_params(axis='y', colors='0.8')\n",
    "plt.xlabel(r\"t90 (GBM, s)\", color=\"0.8\")\n",
    "plt.ylabel(r\"Efficiency (calcualted, unitless)\", color=\"0.8\")\n",
    "Test_2a_Data.to_excel(\"Hypothesis_2a_Data.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
